{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 22:06:32.185885: I tensorflow/core/util/port.cc:110] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-08-10 22:06:32.187099: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-10 22:06:32.211979: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2024-08-10 22:06:32.212494: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-08-10 22:06:32.656299: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: UTF-8 -*-\n",
    "# Â© Kohulan Rajan - 2020\n",
    "import argparse\n",
    "import os\n",
    "import pickle\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Simulate command-line arguments (useful in interactive environments)\n",
    "sys.argv = [\"decimer_transformation/Utils/Create_TFrecord_From_pickles.py\", \"0\",\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Namespace(file=['0', '1'])\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-08-10 22:06:48.884099: I tensorflow/compiler/xla/stream_executor/cuda/cuda_gpu_executor.cc:996] successful NUMA node read from SysFS had negative value (-1), but there must be at least one NUMA node, so returning NUMA node zero. See more at https://github.com/torvalds/linux/blob/v6.0/Documentation/ABI/testing/sysfs-bus-pci#L344-L355\n",
      "2024-08-10 22:06:48.885033: W tensorflow/core/common_runtime/gpu/gpu_device.cc:1956] Cannot dlopen some GPU libraries. Please make sure the missing libraries mentioned above are installed properly if you would like to use GPU. Follow the guide at https://www.tensorflow.org/install/gpu for how to download and setup the required libraries for your platform.\n",
      "Skipping registering GPU devices...\n"
     ]
    }
   ],
   "source": [
    "parser = argparse.ArgumentParser()\n",
    "parser.add_argument(\"file\", nargs=\"+\")\n",
    "\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "# Initial Setup for GPU\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"\n",
    "\n",
    "gpus = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of selected SMILES Strings:  2 \n",
      "\n",
      "Total number of selected SMILES Strings:  2 \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for file_in in args.file:\n",
    "    train_captions = pickle.load(\n",
    "    open(\"pkl/Capts_\" + file_in + \"_\" + file_in + \".pkl\", \"rb\"))\n",
    "    img_name_vector = pickle.load(\n",
    "        open(\"pkl/Images_\" + file_in + \"_\" + file_in + \".pkl\", \"rb\"))\n",
    "\n",
    "    print(\"Total number of selected SMILES Strings: \", len(train_captions), \"\\n\")\n",
    "    # num_shards = int(len(train_captions) / 128)\n",
    "    num_shards = 1 # corresponds to total train files\n",
    "\n",
    "    file_index = num_shards * int(file_in)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = (\n",
    "            value.numpy()\n",
    "        )  # BytesList won't unpack a string from an EagerTensor.\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    def get_train_tfrecord(num_shards, train_captions, img_name_vector, file_index):\n",
    "        print(\"Total number of TFrecords: \", num_shards, flush=True)\n",
    "\n",
    "        for i in range(num_shards):\n",
    "            subsets_num = int(len(train_captions) / num_shards)\n",
    "            sub_split_img_id = img_name_vector[i * subsets_num : (i + 1) * subsets_num]\n",
    "            sub_split_cap_train = train_captions[\n",
    "                i * subsets_num : (i + 1) * subsets_num\n",
    "            ]\n",
    "\n",
    "            tfrecord_name = \"check/\" + \"train-%02d.tfrecord\" % file_index\n",
    "            writer = tf.io.TFRecordWriter(tfrecord_name)\n",
    "            counter = 0\n",
    "            for j in range(len(sub_split_img_id)):\n",
    "                # print(decoded_image.shape)\n",
    "                caption_ = sub_split_cap_train[j]\n",
    "                # image_id_ = sub_split_img_id[counter]\n",
    "                counter = counter + 1\n",
    "                feature = {\n",
    "                    # 'image_id': _bytes_feature(image_id_.encode('utf8')),\n",
    "                    \"image_raw\": _bytes_feature(tf.io.read_file(sub_split_img_id[j])),\n",
    "                    \"caption\": _bytes_feature(caption_.tostring()),\n",
    "                }\n",
    "                example = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "\n",
    "                serialized = example.SerializeToString()\n",
    "                writer.write(serialized)\n",
    "            print(\"%s write to tfrecord success!\" % tfrecord_name, flush=True)\n",
    "            file_index = file_index + 1\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "DECIMER_IMGSEG",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
